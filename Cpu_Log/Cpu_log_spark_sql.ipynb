{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fb6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9007d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Spark-SQL').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f51077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dcc4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DateTime: string (nullable = true)\n",
      " |-- Cpu Count: integer (nullable = true)\n",
      " |-- Cpu Working Time: double (nullable = true)\n",
      " |-- Cpu idle Time: double (nullable = true)\n",
      " |-- cpu_percent: double (nullable = true)\n",
      " |-- Usage Cpu Count : integer (nullable = true)\n",
      " |-- number of software interrupts since boot: integer (nullable = true)\n",
      " |-- number of system calls since boot: integer (nullable = true)\n",
      " |-- number of interrupts since boot: integer (nullable = true)\n",
      " |-- cpu avg load over 1 min: double (nullable = true)\n",
      " |-- cpu avg load over 5 min: double (nullable = true)\n",
      " |-- cpu avg load over 15 min: double (nullable = true)\n",
      " |-- system_total_memory: long (nullable = true)\n",
      " |-- system_used_memory: long (nullable = true)\n",
      " |-- system_free_memory: long (nullable = true)\n",
      " |-- system_active_memory: long (nullable = true)\n",
      " |-- system_inactive_memory: long (nullable = true)\n",
      " |-- system_buffers_memory: integer (nullable = true)\n",
      " |-- system_cached_memory: long (nullable = true)\n",
      " |-- system_shared_memory: integer (nullable = true)\n",
      " |-- system_avalible_memory: long (nullable = true)\n",
      " |-- disk_total_memory: long (nullable = true)\n",
      " |-- disk_used_memory: long (nullable = true)\n",
      " |-- disk_free_memory: long (nullable = true)\n",
      " |-- disk_read_count: integer (nullable = true)\n",
      " |-- disk_write_count: integer (nullable = true)\n",
      " |-- disk_read_bytes: long (nullable = true)\n",
      " |-- disk_write_bytes: long (nullable = true)\n",
      " |-- time spent reading from disk: integer (nullable = true)\n",
      " |-- time spent writing to disk: integer (nullable = true)\n",
      " |-- time spent doing actual I/Os: integer (nullable = true)\n",
      " |-- number of bytes sent: integer (nullable = true)\n",
      " |-- number of bytes received: long (nullable = true)\n",
      " |-- number of packets sent: integer (nullable = true)\n",
      " |-- number of packets recived: integer (nullable = true)\n",
      " |-- total number of errors while receiving: integer (nullable = true)\n",
      " |-- total number of errors while sending: integer (nullable = true)\n",
      " |-- total number of incoming packets which were dropped: integer (nullable = true)\n",
      " |-- total number of outgoing packets which were dropped: integer (nullable = true)\n",
      " |-- boot_time: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- keyboard: double (nullable = true)\n",
      " |-- mouse: double (nullable = true)\n",
      " |-- technology: string (nullable = true)\n",
      " |-- files_changed: integer (nullable = true)\n",
      "\n",
      "Number of rows in the files are:  4122\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"hdfs://localhost:9000//Cpu_Log/*.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "print(\"Number of rows in the files are: \",df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254e6f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           user_name|count|\n",
      "+--------------------+-----+\n",
      "|salinabodale73@gm...|  569|\n",
      "|sharlawar77@gmail...|  580|\n",
      "|rahilstar11@gmail...|  551|\n",
      "|deepshukla292@gma...|  565|\n",
      "|  iamnzm@outlook.com|  614|\n",
      "|markfernandes66@g...|  508|\n",
      "|damodharn21@gmail...|  253|\n",
      "|bhagyashrichalke2...|  482|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('user_name').groupBy('user_name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7125544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a temporary view to perform the cpu log queries.\n",
    "\n",
    "df.createOrReplaceTempView(\"cpu_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f9bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+-----+\n",
      "|         user_name|keyboard|mouse|\n",
      "+------------------+--------+-----+\n",
      "|iamnzm@outlook.com|     1.0| 32.0|\n",
      "|iamnzm@outlook.com|     0.0|  0.0|\n",
      "|iamnzm@outlook.com|     0.0|  0.0|\n",
      "+------------------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2= spark.sql('select user_name, keyboard, mouse from cpu_log').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2810b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|           user_name|count(user_name)|\n",
      "+--------------------+----------------+\n",
      "|salinabodale73@gm...|             440|\n",
      "|sharlawar77@gmail...|             457|\n",
      "|rahilstar11@gmail...|             399|\n",
      "|deepshukla292@gma...|             475|\n",
      "|  iamnzm@outlook.com|             459|\n",
      "|markfernandes66@g...|             389|\n",
      "|damodharn21@gmail...|             191|\n",
      "|bhagyashrichalke2...|             361|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=spark.sql('select user_name, count(user_name) from cpu_log where keyboard != 0 or mouse !=0 group by user_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ad9b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           user_name|avg_work_sec|\n",
      "+--------------------+------------+\n",
      "|salinabodale73@gm...|     22000.0|\n",
      "|sharlawar77@gmail...|     22850.0|\n",
      "|rahilstar11@gmail...|     19950.0|\n",
      "|deepshukla292@gma...|     23750.0|\n",
      "|  iamnzm@outlook.com|     22950.0|\n",
      "|markfernandes66@g...|     19450.0|\n",
      "|damodharn21@gmail...|      9550.0|\n",
      "|bhagyashrichalke2...|     18050.0|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#finding the users with the total average working hours:\n",
    "df2 = spark.sql('select user_name, ((count(user_name)*5*60)/6) as avg_work_sec from cpu_log where keyboard != 0 or mouse !=0 group by user_name')\n",
    "df2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7c6d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+\n",
      "|           user_name|avg_work_sec|avg_work_hrs|\n",
      "+--------------------+------------+------------+\n",
      "|salinabodale73@gm...|     22000.0|         6:6|\n",
      "|deepshukla292@gma...|     23750.0|        6:35|\n",
      "|  iamnzm@outlook.com|     22950.0|        6:22|\n",
      "|sharlawar77@gmail...|     22850.0|        6:20|\n",
      "|rahilstar11@gmail...|     19950.0|        5:32|\n",
      "|markfernandes66@g...|     19450.0|        5:24|\n",
      "|bhagyashrichalke2...|     18050.0|         5:0|\n",
      "|damodharn21@gmail...|      9550.0|        2:39|\n",
      "+--------------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to convert seconds to hours and minutes format for easy readibility\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df3 = df2.withColumn(\"Minutes\", round((col(\"avg_work_sec\")/60),2))\\\n",
    ".withColumn(\"Hours\", floor((col(\"Minutes\")/60)))\\\n",
    ".withColumn(\"hourmin\", floor(col(\"Minutes\")-(col(\"Hours\").cast(\"int\") * 60)))\\\n",
    ".withColumn(\"Days\", floor((col(\"Hours\")/24)))\\\n",
    ".withColumn(\"Days2\", col(\"Days\")*24)\\\n",
    ".withColumn(\"avg_work_hrs\", when((col(\"Hours\")==0) &(col(\"Days\")==0), concat(col(\"hourmin\"),lit(\"min\"))).when((col(\"Hours\")!=0)&(col(\"Days\")==0), concat(col(\"Hours\"),lit(\":\"),col(\"hourmin\"),lit(\"\"))).when(col(\"Days\")!=0, concat(col(\"Days\"),lit(\"d \"),(col(\"Hours\")-col(\"Days2\")),lit(\"hr \"),col(\"hourmin\"),lit(\"min\"))))\\\n",
    ".drop(\"Minutes\",\"Hours\",\"hourmin\",\"Days\",\"Days2\",'wrk_hrs')\\\n",
    ".orderBy(col('avg_work_hrs').desc())\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f592f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           user_name|avg_work_hrs|\n",
      "+--------------------+------------+\n",
      "|salinabodale73@gm...|         6:6|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.createOrReplaceTempView('avg_hour')\n",
    "#printing max worked hr employee\n",
    "df4 = spark.sql('select user_name, avg_work_hrs from avg_hour order by avg_work_hrs desc limit(1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "267f1103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           user_name|avg_work_hrs|\n",
      "+--------------------+------------+\n",
      "|damodharn21@gmail...|        2:39|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing min worked hr employee\n",
    "df4 = spark.sql('select user_name, avg_work_hrs from avg_hour order by avg_work_hrs asc limit(1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84092505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02702cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding users with idle hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddf1fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|           user_name|count(user_name)|\n",
      "+--------------------+----------------+\n",
      "|salinabodale73@gm...|             129|\n",
      "|sharlawar77@gmail...|             123|\n",
      "|rahilstar11@gmail...|             152|\n",
      "|deepshukla292@gma...|              90|\n",
      "|  iamnzm@outlook.com|             155|\n",
      "|markfernandes66@g...|             119|\n",
      "|damodharn21@gmail...|              62|\n",
      "|bhagyashrichalke2...|             121|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = spark.sql('select user_name, count(user_name) from cpu_log where keyboard = 0 and mouse =0 group by user_name').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d130cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           user_name|avg_idle_sec|\n",
      "+--------------------+------------+\n",
      "|salinabodale73@gm...|      6450.0|\n",
      "|sharlawar77@gmail...|      6150.0|\n",
      "|rahilstar11@gmail...|      7600.0|\n",
      "|deepshukla292@gma...|      4500.0|\n",
      "|  iamnzm@outlook.com|      7750.0|\n",
      "|markfernandes66@g...|      5950.0|\n",
      "|damodharn21@gmail...|      3100.0|\n",
      "|bhagyashrichalke2...|      6050.0|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = spark.sql('select user_name, ((count(user_name)*5*60)/6) as avg_idle_sec from cpu_log where keyboard = 0 and mouse =0 group by user_name')\n",
    "df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baba9854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+\n",
      "|           user_name|avg_idle_sec|avg_idle_hrs|\n",
      "+--------------------+------------+------------+\n",
      "|damodharn21@gmail...|      3100.0|       51min|\n",
      "|  iamnzm@outlook.com|      7750.0|         2:9|\n",
      "|rahilstar11@gmail...|      7600.0|         2:6|\n",
      "|salinabodale73@gm...|      6450.0|        1:47|\n",
      "|sharlawar77@gmail...|      6150.0|        1:42|\n",
      "|bhagyashrichalke2...|      6050.0|        1:40|\n",
      "|markfernandes66@g...|      5950.0|        1:39|\n",
      "|deepshukla292@gma...|      4500.0|        1:15|\n",
      "+--------------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6 = df5.withColumn(\"Minutes\", round((col(\"avg_idle_sec\")/60),2))\\\n",
    ".withColumn(\"Hours\", floor((col(\"Minutes\")/60)))\\\n",
    ".withColumn(\"hourmin\", floor(col(\"Minutes\")-(col(\"Hours\").cast(\"int\") * 60)))\\\n",
    ".withColumn(\"Days\", floor((col(\"Hours\")/24)))\\\n",
    ".withColumn(\"Days2\", col(\"Days\")*24)\\\n",
    ".withColumn(\"avg_idle_hrs\", when((col(\"Hours\")==0) &(col(\"Days\")==0), concat(col(\"hourmin\"),lit(\"min\"))).when((col(\"Hours\")!=0)&(col(\"Days\")==0), concat(col(\"Hours\"),lit(\":\"),col(\"hourmin\"),lit(\"\"))).when(col(\"Days\")!=0, concat(col(\"Days\"),lit(\"d \"),(col(\"Hours\")-col(\"Days2\")),lit(\"hr \"),col(\"hourmin\"),lit(\"min\"))))\\\n",
    ".drop(\"Minutes\",\"Hours\",\"hourmin\",\"Days\",\"Days2\",'wrk_hrs')\\\n",
    ".orderBy(col('avg_idle_hrs').desc())\n",
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7b50721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|         user_name|avg_idle_hrs|\n",
      "+------------------+------------+\n",
      "|iamnzm@outlook.com|         2:9|\n",
      "+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.createOrReplaceTempView('idle_hr')\n",
    "#printing highest avg idle hour\n",
    "df7 = spark.sql('select user_name, avg_idle_hrs from idle_hr order by avg_idle_sec desc limit(1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ad234d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           user_name|avg_idle_hrs|\n",
      "+--------------------+------------+\n",
      "|damodharn21@gmail...|       51min|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing lowest avg idle hour\n",
    "df7 = spark.sql('select user_name, avg_idle_hrs from idle_hr order by avg_idle_sec asc limit(1)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436dd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
