{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/24 00:16:58 WARN Utils: Your hostname, Subh-Ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.29.54 instead (on interface wlp4s0)\n",
      "22/02/24 00:16:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/24 00:16:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time_to_Study: integer (nullable = true)\n",
      " |-- Grades: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the Student_Grades_Data.csv file, uploaded in previous step\n",
    "data = spark.read.csv('Sample_StudentGrade.csv', header=True, inferSchema=True)\n",
    "\n",
    "#Taking a look at data type of each column to see what data types inferSchema=TRUE paramter has set for each column\n",
    "data.printSchema() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|Time_to_Study|Grades|\n",
      "+-------------+------+\n",
      "|            1|   1.5|\n",
      "|            5|   2.7|\n",
      "|            7|   3.1|\n",
      "|            3|   2.1|\n",
      "|            2|   1.8|\n",
      "|            9|   3.9|\n",
      "|            6|   2.9|\n",
      "|           12|   4.5|\n",
      "|           11|   4.3|\n",
      "|            2|   1.8|\n",
      "|            4|   2.4|\n",
      "|            8|   3.5|\n",
      "|           13|   4.8|\n",
      "|            9|   3.9|\n",
      "|           14|   5.0|\n",
      "|           10|   4.1|\n",
      "|            6|   2.9|\n",
      "|           12|   4.5|\n",
      "|            1|   1.5|\n",
      "|            4|   2.4|\n",
      "+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display first few rows of data\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Feature array by omitting the last column\n",
    "feature_cols = data.columns[:-1] \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vect_assembler = VectorAssembler(inputCols=feature_cols,outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilize Assembler created above in order to add the feature column\n",
    "data_w_features = vect_assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------+\n",
      "|Time_to_Study|Grades|features|\n",
      "+-------------+------+--------+\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            5|   2.7|   [5.0]|\n",
      "|            7|   3.1|   [7.0]|\n",
      "|            3|   2.1|   [3.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "|            9|   3.9|   [9.0]|\n",
      "|            6|   2.9|   [6.0]|\n",
      "|           12|   4.5|  [12.0]|\n",
      "|           11|   4.3|  [11.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "|            4|   2.4|   [4.0]|\n",
      "|            8|   3.5|   [8.0]|\n",
      "|           13|   4.8|  [13.0]|\n",
      "|            9|   3.9|   [9.0]|\n",
      "|           14|   5.0|  [14.0]|\n",
      "|           10|   4.1|  [10.0]|\n",
      "|            6|   2.9|   [6.0]|\n",
      "|           12|   4.5|  [12.0]|\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            4|   2.4|   [4.0]|\n",
      "+-------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the data having additional column named features. Had it been multiple linear regression problem, you could see all the\n",
    "# independent variable values combined in one list\n",
    "data_w_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|features|Grades|\n",
      "+--------+------+\n",
      "|   [1.0]|   1.5|\n",
      "|   [5.0]|   2.7|\n",
      "|   [7.0]|   3.1|\n",
      "|   [3.0]|   2.1|\n",
      "|   [2.0]|   1.8|\n",
      "|   [9.0]|   3.9|\n",
      "|   [6.0]|   2.9|\n",
      "|  [12.0]|   4.5|\n",
      "|  [11.0]|   4.3|\n",
      "|   [2.0]|   1.8|\n",
      "|   [4.0]|   2.4|\n",
      "|   [8.0]|   3.5|\n",
      "|  [13.0]|   4.8|\n",
      "|   [9.0]|   3.9|\n",
      "|  [14.0]|   5.0|\n",
      "|  [10.0]|   4.1|\n",
      "|   [6.0]|   2.9|\n",
      "|  [12.0]|   4.5|\n",
      "|   [1.0]|   1.5|\n",
      "|   [4.0]|   2.4|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select only Features and Label from previous dataset as we need these two entities for building machine learning model\n",
    "finalized_data = data_w_features.select(\"features\",\"Grades\")\n",
    "\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test model with 70% obs. going in training and 30% in testing\n",
    "train_dataset, test_dataset = finalized_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Grades|\n",
      "+-------+------------------+\n",
      "|  count|                41|\n",
      "|   mean|3.2585365853658534|\n",
      "| stddev|1.1282676122614035|\n",
      "|    min|               1.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Peek into training data\n",
    "train_dataset.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Grades|\n",
      "+-------+------------------+\n",
      "|  count|                 9|\n",
      "|   mean|3.0555555555555554|\n",
      "| stddev|1.0357498625526231|\n",
      "|    min|               1.8|\n",
      "|    max|               4.8|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Peek into test_dataset\n",
    "test_dataset.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/24 00:17:09 WARN Instrumentation: [501822b4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/02/24 00:17:09 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/02/24 00:17:09 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/02/24 00:17:09 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------+\n",
      "|features|Grades|        prediction|\n",
      "+--------+------+------------------+\n",
      "|   [2.0]|   1.8| 1.827805742644454|\n",
      "|   [2.0]|   1.8| 1.827805742644454|\n",
      "|   [4.0]|   2.4|2.3709535625664664|\n",
      "|   [5.0]|   2.7| 2.642527472527473|\n",
      "|   [6.0]|   2.9| 2.914101382488479|\n",
      "|   [7.0]|   3.1|3.1856752924494858|\n",
      "|   [9.0]|   3.9| 3.728823112371498|\n",
      "|  [10.0]|   4.1| 4.000397022332505|\n",
      "|  [13.0]|   4.8| 4.815118752215524|\n",
      "+--------+------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subh/.local/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import Linear Regression class called LinearRegression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "\n",
    "#Create the Linear Regression object named having feature column as features and Label column as Time_to_Study\n",
    "LinReg = LinearRegression(featuresCol=\"features\", labelCol=\"Grades\")\n",
    "\n",
    "#Train the model on the training using fit() method.\n",
    "model = LinReg.fit(train_dataset)\n",
    "\n",
    "#Predict the Grades using the evulate method\n",
    "pred = model.evaluate(test_dataset)\n",
    "\n",
    "#Show the predicted Grade values along side actual Grade values\n",
    "pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of the model is : DenseVector([0.2716])\n"
     ]
    }
   ],
   "source": [
    "#Find out coefficient value using the coefficient property\n",
    "coefficient = model.coefficients\n",
    "print (\"The coefficient of the model is : %a\" %coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intercept of the model is : 1.284658\n"
     ]
    }
   ],
   "source": [
    "#Find out intercept Value\n",
    "intercept = model.intercept\n",
    "print (\"The Intercept of the model is : %f\" %intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.077\n",
      "MSE: 0.006\n",
      "MAE: 0.059\n",
      "r2: 0.994\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluation = RegressionEvaluator(labelCol=\"Grades\", predictionCol=\"prediction\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|features|\n",
      "+--------+\n",
      "|   [2.0]|\n",
      "|   [2.0]|\n",
      "|   [4.0]|\n",
      "|   [5.0]|\n",
      "|   [6.0]|\n",
      "|   [7.0]|\n",
      "|   [9.0]|\n",
      "|  [10.0]|\n",
      "|  [13.0]|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Unlabeled dataset  to contain only feature column\n",
    "unlabeled_dataset = test_dataset.select('features')\n",
    "\n",
    "#Display the content of unlabeled_dataset\n",
    "unlabeled_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the model output for fresh & unseen test data using transform() method\n",
    "new_predictions = model.transform(unlabeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|features|        prediction|\n",
      "+--------+------------------+\n",
      "|   [2.0]| 1.827805742644454|\n",
      "|   [2.0]| 1.827805742644454|\n",
      "|   [4.0]|2.3709535625664664|\n",
      "|   [5.0]| 2.642527472527473|\n",
      "|   [6.0]| 2.914101382488479|\n",
      "|   [7.0]|3.1856752924494858|\n",
      "|   [9.0]| 3.728823112371498|\n",
      "|  [10.0]| 4.000397022332505|\n",
      "|  [13.0]| 4.815118752215524|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the new prediction values\n",
    "new_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model.(10)\n",
    "#prediction = LinReg.pre"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
